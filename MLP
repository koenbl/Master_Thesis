import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV
from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import f1_score, balanced_accuracy_score, precision_score, recall_score, confusion_matrix, classification_report
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline
import seaborn as sns
import matplotlib.pyplot as plt

X = df_testing3[predictors]
y = df_testing3['Sleep quality']

ordinal_encoder = OrdinalEncoder()
y_encoded = ordinal_encoder.fit_transform(y.values.reshape(-1, 1)).flatten()

X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)

scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

mlp_model_with_tuning = MLPClassifier(random_state=42)

param_dist_MLP = {
    'hidden_layer_sizes': [(50, 50), (100,), (100, 50,)],
    'activation': ['tanh', 'relu', 'logistic'],
    'alpha': [0.0001, 0.001, 0.01],
    'learning_rate': ['constant', 'adaptive', 'invscaling'],
    'solver': ['lbfgs', 'sgd', 'adam']
}


cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

random_search_mlp_tuning = RandomizedSearchCV(
    mlp_model_with_tuning,
    param_distributions=param_dist_MLP,
    cv=cv,
    scoring='f1_macro',
    random_state=42,
    n_jobs=-1,
    n_iter=100,
    verbose=1
)

random_search_mlp_tuning.fit(X_train_scaled, y_train)

print("Best Parameters:", random_search_mlp_tuning.best_params_)

best_mlp_model_tuning = random_search_mlp_tuning.best_estimator_

y_cv_pred_mlp_best_tuning = cross_val_predict(best_mlp_model_tuning, X_train_scaled, y_train, cv=cv)

best_mlp_model_tuning.fit(X_train_scaled, y_train)
y_test_pred_mlp_best_tuning = best_mlp_model_tuning.predict(X_test_scaled)

f1_macro_test_mlp_best = f1_score(y_test, y_test_pred_mlp_best_tuning, average='macro')
balanced_acc_test_mlp_best = balanced_accuracy_score(y_test, y_test_pred_mlp_best_tuning)
precision_test_mlp_best = precision_score(y_test, y_test_pred_mlp_best_tuning, average='macro')
recall_test_mlp_best = recall_score(y_test, y_test_pred_mlp_best_tuning, average='macro')

print("\nModel Performance Metrics on Test Set - MLPClassifier with Tuning (Best Model):")
print(f"F1 Macro: {f1_macro_test_mlp_best}")
print(f"Balanced Accuracy: {balanced_acc_test_mlp_best}")
print(f"Precision Macro: {precision_test_mlp_best}")
print(f"Recall Macro: {recall_test_mlp_best}")

print("\nModel Performance Metrics on Test Set - MLPClassifier (Best Model Tuned):")
print(f"F1 Macro tuned MLP: {f1_macro_test_mlp_best}")
print(f"Balanced Accuracy tuned MLP: {balanced_acc_test_mlp_best}")
print(f"Precision Macro tuned MLP: {precision_test_mlp_best}")
print(f"Recall Macro tuned MLP: {recall_test_mlp_best}")

conf_mat_test_mlp_best_tuning = confusion_matrix(y_test, y_test_pred_mlp_best_tuning)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat_test_mlp_best_tuning, annot=True, fmt="d", cmap="Blues", xticklabels=original_classes, yticklabels=original_classes)
plt.title("Confusion Matrix - MLPClassifier - Tuned")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

print("\nClassification Report - MLPClassifier (Best Model):")
print(classification_report(y_test, y_test_pred_mlp_best_tuning, digits=3))


## + SMOTE


X = df_testing3[predictors]
y = df_testing3['Sleep quality']

ordinal_encoder = OrdinalEncoder()
y_encoded = ordinal_encoder.fit_transform(y.values.reshape(-1, 1)).flatten()

X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)

scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

param_dist_MLP = {
    'mlpclassifier__hidden_layer_sizes': [(50, 50), (100,), (100, 50)],
    'mlpclassifier__activation': ['tanh', 'relu', 'logistic'],
    'mlpclassifier__alpha': [0.0001, 0.001, 0.01],
    'mlpclassifier__learning_rate': ['constant', 'adaptive', 'invscaling'],
    'mlpclassifier__solver': ['lbfgs', 'sgd', 'adam']
}

imba_pipeline_MLP_tuning_smote = Pipeline([
    ('smote', SMOTE(random_state=42)),
    ('mlpclassifier', MLPClassifier(random_state=42))
])
search_imba_MLP_tuned_smote = RandomizedSearchCV(imba_pipeline_MLP_tuning_smote, param_distributions=param_dist_MLP, cv=cv, scoring='f1_macro',
                                  return_train_score=True, random_state=42, n_jobs=-1, n_iter=100, verbose=1)
search_imba_MLP_tuned_smote.fit(X_train_scaled, y_train)

print("Best Parameters:", search_imba_MLP_tuned_smote.best_params_)

y_test_predict_MLP_smote = search_imba_MLP_tuned_smote.predict(X_test_scaled)

f1_macro_test_imba_MLP_smote = f1_score(y_test, y_test_predict_MLP_smote, average='macro')
balanced_acc_test_imba_MLP_smote = balanced_accuracy_score(y_test, y_test_predict_MLP_smote)
precision_test_imba_MLP_smote = precision_score(y_test, y_test_predict_MLP_smote, average='macro')
recall_test_imba_MLP_smote = recall_score(y_test, y_test_predict_MLP_smote, average='macro')

print("\nModel Performance Metrics on Test Set - Logistic Regression with SMOTE (Best Model):")
print(f"F1 Macro: {f1_macro_test_imba_MLP_smote}")
print(f"Balanced Accuracy: {balanced_acc_test_imba_MLP_smote}")
print(f"Precision Macro: {precision_test_imba_MLP_smote}")
print(f"Recall Macro: {recall_test_imba_MLP_smote}")

conf_mat_test_MLP_tuned_smote = confusion_matrix(y_test, y_test_predict_MLP_smote)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat_test_MLP_tuned_smote, annot=True, fmt="d", cmap="Blues", xticklabels=original_classes, yticklabels=original_classes)
plt.title("Confusion Matrix - MLP - Tuned - SMOTE")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

print("\nClassification Report - Logistic Regression with SMOTE (Best Model):")
print(classification_report(y_test, y_test_predict_MLP_smote, digits=3))

